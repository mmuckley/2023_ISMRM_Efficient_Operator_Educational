{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as  np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from effop import FiniteDifferenceL1, SenseNufftOp, PrimalDualL1\n",
    "\n",
    "device = torch.device(\"cpu\")  # use this for CPU\n",
    "# device = torch.device(\"cuda\")  # use this for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open(\"../data_loc.yaml\", \"r\") as f:\n",
    "    data_file = yaml.safe_load(f)\n",
    "\n",
    "raw_data = sio.loadmat(data_file)\n",
    "dcomp = torch.tensor(raw_data[\"w\"]).permute(1, 0)\n",
    "# precompensate k-space with density compensation\n",
    "# kdata = torch.tensor(raw_data[\"kdata\"]).permute(1, 0, 2) * dcomp.sqrt().unsqueeze(-1)\n",
    "kdata = torch.tensor(raw_data[\"kdata\"]).permute(1, 0, 2)\n",
    "ktraj = torch.tensor(raw_data[\"k\"]).permute(1, 0) * 2 * np.pi\n",
    "sensitivity_maps = (\n",
    "    torch.tensor(np.transpose(raw_data[\"b1\"], (2, 1, 0))).unsqueeze(0).contiguous()\n",
    ").to(device)\n",
    "sensitivity_maps = sensitivity_maps / sensitivity_maps.abs().max()\n",
    "\n",
    "# resort k-space based on temporal resolution\n",
    "nspokes = 21\n",
    "num_timepoints = math.floor(kdata.shape[0] / nspokes)\n",
    "num_coils = kdata.shape[-1]\n",
    "kdata = (\n",
    "    kdata[: nspokes * num_timepoints]\n",
    "    .reshape(num_timepoints, -1, num_coils)\n",
    "    .permute(0, 2, 1)\n",
    "    .contiguous()\n",
    ").to(device)\n",
    "dcomp = dcomp * dcomp.shape[0] / nspokes\n",
    "dcomp = torch.real(dcomp[: nspokes * num_timepoints].reshape(num_timepoints, 1, -1).contiguous()).to(device)\n",
    "ktraj = ktraj[: nspokes * num_timepoints].reshape(num_timepoints, -1).contiguous()\n",
    "ktraj = torch.stack((torch.imag(ktraj), torch.real(ktraj)), dim=1).contiguous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the operators\n",
    "data_op = SenseNufftOp(sensitivity_maps, ktraj).to(device)\n",
    "\n",
    "# initial estimate\n",
    "with torch.no_grad():\n",
    "    orig_est = data_op.adjoint(dcomp * kdata) / torch.sum(\n",
    "        sensitivity_maps.abs() ** 2, dim=1, keepdim=True\n",
    "    )\n",
    "\n",
    "reg_op = FiniteDifferenceL1(lam=0.25 * orig_est.abs().max()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to None to estimate the step size\n",
    "sense_eig = 14.5\n",
    "# run a power iteration\n",
    "if sense_eig is None:\n",
    "    vec = torch.randn_like(orig_est)\n",
    "    for ite in range(30):\n",
    "        vec = data_op.adjoint(dcomp * data_op.forward(vec / torch.norm(vec)))\n",
    "        print(torch.norm(vec))\n",
    "\n",
    "    sense_eig = torch.norm(vec)\n",
    "\n",
    "# this is analytical\n",
    "reg_eig = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frac_high = 0.7\n",
    "frac_low = 0.1\n",
    "new_est = orig_est / orig_est.abs().max()\n",
    "new_est[new_est.abs() > frac_high] = frac_high\n",
    "new_est[new_est.abs() < frac_low] = 0.0\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(new_est[0][0].abs().permute(1, 0).flip(0).cpu().numpy())\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.gray()\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.imshow(torch.sum(sensitivity_maps.abs() ** 2, dim=1)[0].permute(1, 0).flip(0).numpy())\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the optimizer\n",
    "opt = PrimalDualL1(\n",
    "    data_operator=data_op,\n",
    "    data_bound=sense_eig,\n",
    "    reg_operator=reg_op,\n",
    "    reg_bound=reg_eig,\n",
    "    num_iterations=8,\n",
    "    data_weights=dcomp,\n",
    ")\n",
    "\n",
    "# optimize!\n",
    "with torch.no_grad():\n",
    "    est = opt.solve(kdata, orig_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.figure(0)\n",
    "frac_high = 0.7\n",
    "frac_low = 0.1\n",
    "new_est = est / est.abs().max()\n",
    "new_est[new_est.abs() > frac_high] = frac_high\n",
    "new_est[new_est.abs() < frac_low] = 0.0\n",
    "new_est = new_est.permute(0, 3, 2, 1).flip(1)\n",
    "new_est = torch.floor(new_est.abs() * 255.0 + 0.5).to(torch.uint8).repeat(1, 1, 1, 3)\n",
    "video = new_est.cpu().numpy()\n",
    "print(video.shape)\n",
    "\n",
    "# confert to video)\n",
    "fig = plt.figure(0)\n",
    "fig.set_size_inches(5, 5)\n",
    "ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "im = ax.imshow(video[0, ...], aspect=\"equal\")\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    im.set_data(video[0,:,:,:])\n",
    "\n",
    "def animate(i):\n",
    "    im.set_data(video[i, ...])\n",
    "    return im\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig,\n",
    "    animate,\n",
    "    init_func=init,\n",
    "    frames=video.shape[0],\n",
    "    interval=100,\n",
    ")\n",
    "# anim.save(\"video.mp4\")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
